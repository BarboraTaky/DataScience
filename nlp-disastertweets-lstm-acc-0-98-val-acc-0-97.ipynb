{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/barborakudlov/nlp-disastertweets-lstm-acc-0-98-val-acc-0-97?scriptVersionId=119887235\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.034836,"end_time":"2023-02-20T01:34:07.663863","exception":false,"start_time":"2023-02-20T01:34:07.629027","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:38.108545Z","iopub.execute_input":"2023-02-21T17:24:38.108949Z","iopub.status.idle":"2023-02-21T17:24:38.117176Z","shell.execute_reply.started":"2023-02-21T17:24:38.108913Z","shell.execute_reply":"2023-02-21T17:24:38.115961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import the Necessary Libraries","metadata":{}},{"cell_type":"code","source":"#For modelling NLP\nimport tensorflow as tf \nimport tensorflow_hub as hub","metadata":{"papermill":{"duration":7.48183,"end_time":"2023-02-20T01:34:15.155235","exception":false,"start_time":"2023-02-20T01:34:07.673405","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:38.123058Z","iopub.execute_input":"2023-02-21T17:24:38.123623Z","iopub.status.idle":"2023-02-21T17:24:38.128515Z","shell.execute_reply.started":"2023-02-21T17:24:38.123577Z","shell.execute_reply":"2023-02-21T17:24:38.12749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#For cleaning\nimport spacy \nimport nltk \nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords \nimport regex as re \nimport string \n\n#For visualizing\nimport matplotlib.pyplot as plt \nimport seaborn as sns \npd.set_option('display.max_colwidth', None)\n\n#For modelling NLP\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding\nfrom tensorflow.keras.models import Sequential","metadata":{"papermill":{"duration":6.785722,"end_time":"2023-02-20T01:34:21.950727","exception":false,"start_time":"2023-02-20T01:34:15.165005","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:38.131233Z","iopub.execute_input":"2023-02-21T17:24:38.131831Z","iopub.status.idle":"2023-02-21T17:24:38.142845Z","shell.execute_reply.started":"2023-02-21T17:24:38.131779Z","shell.execute_reply":"2023-02-21T17:24:38.141855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import the Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\n\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\n\nids = test.id","metadata":{"papermill":{"duration":0.080579,"end_time":"2023-02-20T01:34:22.041655","exception":false,"start_time":"2023-02-20T01:34:21.961076","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:38.144742Z","iopub.execute_input":"2023-02-21T17:24:38.145757Z","iopub.status.idle":"2023-02-21T17:24:38.177804Z","shell.execute_reply.started":"2023-02-21T17:24:38.145688Z","shell.execute_reply":"2023-02-21T17:24:38.176228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('shape of training set: ', train.shape)\nprint('shape of testing set: ', test.shape)","metadata":{"papermill":{"duration":0.01983,"end_time":"2023-02-20T01:34:22.070718","exception":false,"start_time":"2023-02-20T01:34:22.050888","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:38.179746Z","iopub.execute_input":"2023-02-21T17:24:38.180099Z","iopub.status.idle":"2023-02-21T17:24:38.185613Z","shell.execute_reply.started":"2023-02-21T17:24:38.180057Z","shell.execute_reply":"2023-02-21T17:24:38.184571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Analysing- Missing values","metadata":{}},{"cell_type":"code","source":"#Concatenating the traind and test data\ndf_concat = pd.concat([train, test], axis=0).reset_index(drop=True)\n\nnulls = pd.DataFrame(np.c_[df_concat.isnull().sum(), (df_concat.isnull().sum()/len(df_concat))*100], \n                     columns=['# of nulls', '% of nulls'], \n                     index=df_concat.columns)\n\nnulls","metadata":{"papermill":{"duration":0.040932,"end_time":"2023-02-20T01:34:22.121889","exception":false,"start_time":"2023-02-20T01:34:22.080957","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:38.187389Z","iopub.execute_input":"2023-02-21T17:24:38.188051Z","iopub.status.idle":"2023-02-21T17:24:38.209724Z","shell.execute_reply.started":"2023-02-21T17:24:38.188017Z","shell.execute_reply":"2023-02-21T17:24:38.208633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for df in [train, test, df_concat]:\n    df['keyword'].fillna('no_keyword', inplace=True)\n    df['location'].fillna('no_location', inplace=True)","metadata":{"papermill":{"duration":0.022138,"end_time":"2023-02-20T01:34:22.153794","exception":false,"start_time":"2023-02-20T01:34:22.131656","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:38.212007Z","iopub.execute_input":"2023-02-21T17:24:38.212433Z","iopub.status.idle":"2023-02-21T17:24:38.223914Z","shell.execute_reply.started":"2023-02-21T17:24:38.212398Z","shell.execute_reply":"2023-02-21T17:24:38.222857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_concat.groupby('location')['text'].count().sort_values(ascending=False)","metadata":{"papermill":{"duration":0.028331,"end_time":"2023-02-20T01:34:22.191644","exception":false,"start_time":"2023-02-20T01:34:22.163313","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:38.225516Z","iopub.execute_input":"2023-02-21T17:24:38.225893Z","iopub.status.idle":"2023-02-21T17:24:38.245342Z","shell.execute_reply.started":"2023-02-21T17:24:38.225859Z","shell.execute_reply":"2023-02-21T17:24:38.244446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing the data keywords","metadata":{}},{"cell_type":"markdown","source":"- keywords have really important impact on if tweet is reporting disasters or non-disasters event","metadata":{}},{"cell_type":"code","source":"#seperation of disasters and non-disasters tweets and group them by this keywords, what are the most repeated\ncount_dis_keywords = train[train['target'] == 1].groupby('keyword').count().sort_values(by='target', ascending=False)[:20]\n\ncount_non_dis_keywords = train[train['target'] == 0].groupby('keyword').count().sort_values(by='target', ascending=False)[:20]\n\nsns.set(style=\"white\")\n\nfig, axs = plt.subplots(1, 2, figsize=(25, 8))\n\n#left plot- disasters keywords\nsns.barplot(x=count_dis_keywords['target'], \n            y=count_dis_keywords.index,\n            ax=axs[0],\n            palette='Reds_r',\n            label='dis')\n\n#right plot- non-disasters keywords\nsns.barplot(x=count_non_dis_keywords['target'], \n            y=count_non_dis_keywords.index,\n            ax=axs[1],\n            palette='Greens_d',\n            label='non_dis')\n\nfor ax in [axs[0], axs[1]]:\n    ax.set_title('Number of tweets per keyword', fontsize=15)\n    ax.set_ylabel('')\n    ax.set_xlabel('')\n    ax.set_yticklabels(labels=ax.get_yticklabels(), fontsize=15)","metadata":{"papermill":{"duration":0.925009,"end_time":"2023-02-20T01:34:23.12633","exception":false,"start_time":"2023-02-20T01:34:22.201321","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:38.2487Z","iopub.execute_input":"2023-02-21T17:24:38.248969Z","iopub.status.idle":"2023-02-21T17:24:39.093876Z","shell.execute_reply.started":"2023-02-21T17:24:38.248946Z","shell.execute_reply":"2023-02-21T17:24:39.092759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- we can see from red left plot, that a lot of disasters tweets do not have any keywords ()\n- we can see from green green plot, that a data arent cleaned because of body%20bags so it will be the next step to classify the text as best as we can","metadata":{}},{"cell_type":"code","source":"#dropping the columns with a lot of NaN values\nfor df in [train, test, df_concat]:\n    df.drop(columns=['location', 'keyword', 'id'], inplace=True)","metadata":{"papermill":{"duration":0.02487,"end_time":"2023-02-20T01:34:23.163176","exception":false,"start_time":"2023-02-20T01:34:23.138306","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:39.09546Z","iopub.execute_input":"2023-02-21T17:24:39.096438Z","iopub.status.idle":"2023-02-21T17:24:39.106024Z","shell.execute_reply.started":"2023-02-21T17:24:39.096398Z","shell.execute_reply":"2023-02-21T17:24:39.104984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NLP Pipeline- Normalization(cleaning)","metadata":{}},{"cell_type":"code","source":"#for cleaning we will use 2 libraries- NLTK and SpaCy and in the end, we will choose the best one from these two ith the best result\nnlp = spacy.load('en_core_web_sm')\nsp = spacy.load('en_core_web_sm')\n\nnltk.download('stopwords')\nnltk.download('punkt')\n\nspacy_st = nlp.Defaults.stop_words\nnltk_st = stopwords.words('english')","metadata":{"papermill":{"duration":2.19455,"end_time":"2023-02-20T01:34:25.369684","exception":false,"start_time":"2023-02-20T01:34:23.175134","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:39.107691Z","iopub.execute_input":"2023-02-21T17:24:39.108072Z","iopub.status.idle":"2023-02-21T17:24:40.8089Z","shell.execute_reply.started":"2023-02-21T17:24:39.108038Z","shell.execute_reply":"2023-02-21T17:24:40.807888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean1(tweet, http=True, punc=True, lem=True, stop_w=True):\n    \n    #substituion all the parts of the text, that has this formats \n    if http == True:\n        tweet = re.sub('https?:\\/\\/t.co\\/[A-Za-z0-9]*', '', tweet)\n    \n    #choose only one from NLTK or SpaCy with the best results\n    if stop_w == 'nltk':\n        tweet = [word for word in word_tokenize(tweet) if not word.lower() in nltk_st]\n        tweet = ' '.join(tweet)\n    \n    #SpaCy has more stopwords around 400- so it can delete larger parts for my text, so that is the reason, that we will firstly use NLTK\n    elif stop_w == 'spacy':\n        tweet = [word for word in word_tokenize(tweet) if not word.lower() in spacy_st]\n        tweet = ' '.join(tweet)\n      \n    \n    #lemmitizing\n    if lem == True:\n        lemmatized = [word.lemma_ for word in sp(tweet)]\n        tweet = ' '.join(lemmatized)\n    \n    #punctionation removal using translate- substitueting with blank space\n    #Punctuation marks are symbols such as period (.), comma (,), semicolon (;), colon (:), question mark (?), exclamation mark (!), parentheses (), brackets [], braces {}, quotation marks \"\", apostrophe ('), and many others.\n    if punc == True:\n        tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n    \n    #removing the extra space that may be around words or letters\n    tweet = re.sub('\\s+', ' ', tweet)\n    \n    return tweet\n\ndef clean2(text):\n    text = text.lower()\n    text = re.sub(r\"what's\", \"what is \", text)\n    text = re.sub(r\"\\'s\", \" \", text)\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"can't\", \"cannot \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"i'm\", \"i am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n    text = re.sub('\\W', ' ', text)\n    text = re.sub('\\s+', ' ', text)\n    text = text.strip(' ')\n    return text","metadata":{"papermill":{"duration":0.025807,"end_time":"2023-02-20T01:34:25.428863","exception":false,"start_time":"2023-02-20T01:34:25.403056","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:40.812525Z","iopub.execute_input":"2023-02-21T17:24:40.812843Z","iopub.status.idle":"2023-02-21T17:24:40.82431Z","shell.execute_reply.started":"2023-02-21T17:24:40.812794Z","shell.execute_reply":"2023-02-21T17:24:40.823197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_concat['cleaned_text'] = df_concat['text'].apply(lambda x: clean1(x, lem=False, stop_w='nltk', http=True, punc=True)).apply(lambda x: clean2(x)) #This code will output the cleaned text for each tweet in the DataFrame (after clean1 and clean2)\n\n# df_concat['cleaned_text'] = [nlp(text) for text in df_concat['cleaned_text']]","metadata":{"papermill":{"duration":3.175243,"end_time":"2023-02-20T01:34:28.614916","exception":false,"start_time":"2023-02-20T01:34:25.439673","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:40.82585Z","iopub.execute_input":"2023-02-21T17:24:40.826383Z","iopub.status.idle":"2023-02-21T17:24:43.860438Z","shell.execute_reply.started":"2023-02-21T17:24:40.826345Z","shell.execute_reply":"2023-02-21T17:24:43.859442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#split the train and test data back\ncleaned_train = df_concat[:train.shape[0]] # So cleaned_train will contain the first train.shape[0] rows of df_concat, which are assumed to be the rows used for training a model.\n\ncleaned_test = df_concat[train.shape[0]:]\n\ncleaned_train.drop(columns=['text'], inplace=True)\n\ncleaned_test.drop(columns=['text'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-21T17:24:43.861895Z","iopub.execute_input":"2023-02-21T17:24:43.862465Z","iopub.status.idle":"2023-02-21T17:24:43.872859Z","shell.execute_reply.started":"2023-02-21T17:24:43.862429Z","shell.execute_reply":"2023-02-21T17:24:43.871748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_train","metadata":{"papermill":{"duration":0.027581,"end_time":"2023-02-20T01:34:28.695167","exception":false,"start_time":"2023-02-20T01:34:28.667586","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:43.874212Z","iopub.execute_input":"2023-02-21T17:24:43.875212Z","iopub.status.idle":"2023-02-21T17:24:43.892038Z","shell.execute_reply.started":"2023-02-21T17:24:43.875177Z","shell.execute_reply":"2023-02-21T17:24:43.89096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_total = df_concat['cleaned_text']\n\nX_train = cleaned_train['cleaned_text']\ny_train = cleaned_train['target']\n\nX_test = cleaned_test['cleaned_text']","metadata":{"papermill":{"duration":0.019838,"end_time":"2023-02-20T01:34:28.727097","exception":false,"start_time":"2023-02-20T01:34:28.707259","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:43.893512Z","iopub.execute_input":"2023-02-21T17:24:43.893947Z","iopub.status.idle":"2023-02-21T17:24:43.901073Z","shell.execute_reply.started":"2023-02-21T17:24:43.893914Z","shell.execute_reply":"2023-02-21T17:24:43.900093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#?? zeptat se Standy\nvectorizers = CountVectorizer(binary=True, \n                              ngram_range=(1, 3), \n                              stop_words='english')\n\nX_total_vectors = vectorizers.fit_transform(X_total)\n\nprint(vectorizers.get_feature_names_out())\n\nprint(X_total_vectors.toarray())","metadata":{"papermill":{"duration":0.019151,"end_time":"2023-02-20T01:34:28.758773","exception":false,"start_time":"2023-02-20T01:34:28.739622","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:29:51.777421Z","iopub.execute_input":"2023-02-21T17:29:51.777827Z","iopub.status.idle":"2023-02-21T17:29:52.723897Z","shell.execute_reply.started":"2023-02-21T17:29:51.777775Z","shell.execute_reply":"2023-02-21T17:29:52.722833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Word Embeddings","metadata":{"papermill":{"duration":0.012016,"end_time":"2023-02-20T01:34:28.782852","exception":false,"start_time":"2023-02-20T01:34:28.770836","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Suport Vector Machine(SVM)","metadata":{}},{"cell_type":"code","source":"# zeptat se Standy??\nfrom sklearn import svm # Support Vector Machine (SVM) classifier is being used to classify the text data\n\nclf_svm = svm.SVC(kernel='linear')\n\nX_train_vectors = vectorizers.transform(X_train)\n\nclf_svm.fit(X_train_vectors, y_train)","metadata":{"papermill":{"duration":0.019432,"end_time":"2023-02-20T01:34:28.814867","exception":false,"start_time":"2023-02-20T01:34:28.795435","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:33:55.108895Z","iopub.execute_input":"2023-02-21T17:33:55.109277Z","iopub.status.idle":"2023-02-21T17:34:04.031516Z","shell.execute_reply.started":"2023-02-21T17:33:55.109245Z","shell.execute_reply":"2023-02-21T17:34:04.03052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_vectors = vectorizers.transform(X_test)\n\nprint(vectorizers.get_feature_names_out())\n\nprint(X_test_vectors.toarray())","metadata":{"papermill":{"duration":0.019129,"end_time":"2023-02-20T01:34:28.845666","exception":false,"start_time":"2023-02-20T01:34:28.826537","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:34:12.007141Z","iopub.execute_input":"2023-02-21T17:34:12.007533Z","iopub.status.idle":"2023-02-21T17:34:12.287997Z","shell.execute_reply.started":"2023-02-21T17:34:12.007503Z","shell.execute_reply":"2023-02-21T17:34:12.286857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_sample = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\n\n# sub_sample","metadata":{"papermill":{"duration":0.019306,"end_time":"2023-02-20T01:34:28.876879","exception":false,"start_time":"2023-02-20T01:34:28.857573","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:43.93707Z","iopub.execute_input":"2023-02-21T17:24:43.937329Z","iopub.status.idle":"2023-02-21T17:24:43.941335Z","shell.execute_reply.started":"2023-02-21T17:24:43.937306Z","shell.execute_reply":"2023-02-21T17:24:43.940233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_sample['target'] = clf_svm.predict(X_test_vectors)\n\n# sub_sample['target'] = sub_sample['target'].astype('int')\n\n# sub_sample.to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":0.018544,"end_time":"2023-02-20T01:34:28.906564","exception":false,"start_time":"2023-02-20T01:34:28.88802","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:43.943201Z","iopub.execute_input":"2023-02-21T17:24:43.943536Z","iopub.status.idle":"2023-02-21T17:24:43.950509Z","shell.execute_reply.started":"2023-02-21T17:24:43.943504Z","shell.execute_reply":"2023-02-21T17:24:43.949405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission = pd.read_csv('/kaggle/working/submission.csv')\n\n# submission","metadata":{"papermill":{"duration":0.018057,"end_time":"2023-02-20T01:34:28.935948","exception":false,"start_time":"2023-02-20T01:34:28.917891","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:43.952382Z","iopub.execute_input":"2023-02-21T17:24:43.952782Z","iopub.status.idle":"2023-02-21T17:24:43.95847Z","shell.execute_reply.started":"2023-02-21T17:24:43.952748Z","shell.execute_reply":"2023-02-21T17:24:43.957284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bidirectional LSTM","metadata":{"papermill":{"duration":0.011454,"end_time":"2023-02-20T01:34:28.958508","exception":false,"start_time":"2023-02-20T01:34:28.947054","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from tensorflow.keras.layers import TextVectorization ","metadata":{"papermill":{"duration":0.021135,"end_time":"2023-02-20T01:34:28.991412","exception":false,"start_time":"2023-02-20T01:34:28.970277","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:43.960216Z","iopub.execute_input":"2023-02-21T17:24:43.960555Z","iopub.status.idle":"2023-02-21T17:24:43.967013Z","shell.execute_reply.started":"2023-02-21T17:24:43.960522Z","shell.execute_reply":"2023-02-21T17:24:43.966156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_total = df_concat['cleaned_text']\n\nX_train = cleaned_train['cleaned_text']\ny_train = cleaned_train['target'].values\n\nX_test = cleaned_test['cleaned_text']","metadata":{"papermill":{"duration":0.019391,"end_time":"2023-02-20T01:34:29.022216","exception":false,"start_time":"2023-02-20T01:34:29.002825","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:43.968122Z","iopub.execute_input":"2023-02-21T17:24:43.96918Z","iopub.status.idle":"2023-02-21T17:24:43.977043Z","shell.execute_reply.started":"2023-02-21T17:24:43.969146Z","shell.execute_reply":"2023-02-21T17:24:43.976161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_total), len(X_train), len(X_test)","metadata":{"papermill":{"duration":0.021023,"end_time":"2023-02-20T01:34:29.054524","exception":false,"start_time":"2023-02-20T01:34:29.033501","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:43.980304Z","iopub.execute_input":"2023-02-21T17:24:43.980627Z","iopub.status.idle":"2023-02-21T17:24:43.991125Z","shell.execute_reply.started":"2023-02-21T17:24:43.980602Z","shell.execute_reply":"2023-02-21T17:24:43.990247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define for Embeddings- zeptat se Standy?\nMAX_FEATURES = 20000 #  20 000most frequent words in the input text data.\n\nvectorizer = TextVectorization(max_tokens=MAX_FEATURES, \n                               output_sequence_length=200, \n                               output_mode='int')","metadata":{"papermill":{"duration":8.799837,"end_time":"2023-02-20T01:34:37.865526","exception":false,"start_time":"2023-02-20T01:34:29.065689","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:43.992284Z","iopub.execute_input":"2023-02-21T17:24:43.993277Z","iopub.status.idle":"2023-02-21T17:24:44.00353Z","shell.execute_reply.started":"2023-02-21T17:24:43.993243Z","shell.execute_reply":"2023-02-21T17:24:44.002862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer.adapt(X_total.values)\n\nvectorizer.get_vocabulary()","metadata":{"papermill":{"duration":0.870642,"end_time":"2023-02-20T01:34:38.748005","exception":false,"start_time":"2023-02-20T01:34:37.877363","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:44.004885Z","iopub.execute_input":"2023-02-21T17:24:44.006162Z","iopub.status.idle":"2023-02-21T17:24:44.678422Z","shell.execute_reply.started":"2023-02-21T17:24:44.006128Z","shell.execute_reply":"2023-02-21T17:24:44.677481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizerd_text = vectorizer(X_train.values)\n\ndataset = tf.data.Dataset.from_tensor_slices((vectorizerd_text, y_train))\ndataset = dataset.cache()\ndataset = dataset.shuffle(160000)\ndataset = dataset.batch(32) \ndataset = dataset.prefetch(8)","metadata":{"papermill":{"duration":0.109182,"end_time":"2023-02-20T01:34:38.870019","exception":false,"start_time":"2023-02-20T01:34:38.760837","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:44.680041Z","iopub.execute_input":"2023-02-21T17:24:44.680399Z","iopub.status.idle":"2023-02-21T17:24:44.723765Z","shell.execute_reply.started":"2023-02-21T17:24:44.680365Z","shell.execute_reply":"2023-02-21T17:24:44.722855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_X, batch_y = dataset.as_numpy_iterator().next()\n\nbatch_X.shape, batch_y.shape","metadata":{"papermill":{"duration":0.059,"end_time":"2023-02-20T01:34:38.942305","exception":false,"start_time":"2023-02-20T01:34:38.883305","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:44.725937Z","iopub.execute_input":"2023-02-21T17:24:44.726635Z","iopub.status.idle":"2023-02-21T17:24:44.765711Z","shell.execute_reply.started":"2023-02-21T17:24:44.726597Z","shell.execute_reply":"2023-02-21T17:24:44.764861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset)\n\ntrain = dataset.take(int(len(dataset)*.7))\nval = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\ntest = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))","metadata":{"papermill":{"duration":0.028143,"end_time":"2023-02-20T01:34:38.983453","exception":false,"start_time":"2023-02-20T01:34:38.95531","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:44.767243Z","iopub.execute_input":"2023-02-21T17:24:44.767595Z","iopub.status.idle":"2023-02-21T17:24:44.779387Z","shell.execute_reply.started":"2023-02-21T17:24:44.767562Z","shell.execute_reply":"2023-02-21T17:24:44.778435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train), len(val), len(test)","metadata":{"papermill":{"duration":0.023082,"end_time":"2023-02-20T01:34:39.019511","exception":false,"start_time":"2023-02-20T01:34:38.996429","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:44.781798Z","iopub.execute_input":"2023-02-21T17:24:44.782407Z","iopub.status.idle":"2023-02-21T17:24:44.789421Z","shell.execute_reply.started":"2023-02-21T17:24:44.782371Z","shell.execute_reply":"2023-02-21T17:24:44.788322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Embedding(MAX_FEATURES + 1, 64))\nmodel.add(Bidirectional(LSTM(64, activation='tanh')))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='BinaryCrossentropy', optimizer='Adam', metrics=['accuracy'])\n\nmodel.summary()","metadata":{"papermill":{"duration":0.614611,"end_time":"2023-02-20T01:34:39.646438","exception":false,"start_time":"2023-02-20T01:34:39.031827","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:44.791514Z","iopub.execute_input":"2023-02-21T17:24:44.792043Z","iopub.status.idle":"2023-02-21T17:24:45.939543Z","shell.execute_reply.started":"2023-02-21T17:24:44.792009Z","shell.execute_reply":"2023-02-21T17:24:45.938774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist= model.fit(train, epochs=30, batch_size=32, validation_data=val)","metadata":{"papermill":{"duration":133.154723,"end_time":"2023-02-20T01:36:52.815811","exception":false,"start_time":"2023-02-20T01:34:39.661088","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:24:45.940755Z","iopub.execute_input":"2023-02-21T17:24:45.941114Z","iopub.status.idle":"2023-02-21T17:26:59.5008Z","shell.execute_reply.started":"2023-02-21T17:24:45.941079Z","shell.execute_reply":"2023-02-21T17:26:59.499856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\n\npd.DataFrame(hist.history).plot()\n\nplt.show()","metadata":{"papermill":{"duration":0.553806,"end_time":"2023-02-20T01:36:53.4814","exception":false,"start_time":"2023-02-20T01:36:52.927594","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:26:59.502533Z","iopub.execute_input":"2023-02-21T17:26:59.502907Z","iopub.status.idle":"2023-02-21T17:26:59.773385Z","shell.execute_reply.started":"2023-02-21T17:26:59.50287Z","shell.execute_reply":"2023-02-21T17:26:59.772456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy","metadata":{"papermill":{"duration":0.256656,"end_time":"2023-02-20T01:36:54.007563","exception":false,"start_time":"2023-02-20T01:36:53.750907","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:26:59.774684Z","iopub.execute_input":"2023-02-21T17:26:59.775527Z","iopub.status.idle":"2023-02-21T17:26:59.780669Z","shell.execute_reply.started":"2023-02-21T17:26:59.77549Z","shell.execute_reply":"2023-02-21T17:26:59.779363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre = Precision()\nre = Recall()\nacc = CategoricalAccuracy()\n\ndef output(num):\n    if num <= 0.5:\n        return 0\n    else: \n        return 1\n    \n\nfor batch in test.as_numpy_iterator():\n    \n    X_true, y_true = batch\n    \n    y_batchout = []\n    \n    yhat = model.predict(X_true)\n    \n    for num in yhat:\n        y_batchout.append(output(num))\n    \n#     y_true = y_true.flatten()\n#     yout = yout.flatten()\n    \n    print(y_true), print(y_batchout)\n    \n    pre.update_state(y_true, y_batchout)\n    re.update_state(y_true, y_batchout)\n    acc.update_state(y_true, y_batchout)\n\nprint(f'Precision: {pre.result().numpy()}, Recall: {re.result().numpy()}, Accuracy: {acc.result().numpy()}')","metadata":{"papermill":{"duration":2.476011,"end_time":"2023-02-20T01:36:56.83447","exception":false,"start_time":"2023-02-20T01:36:54.358459","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:26:59.782218Z","iopub.execute_input":"2023-02-21T17:26:59.782563Z","iopub.status.idle":"2023-02-21T17:27:01.809397Z","shell.execute_reply.started":"2023-02-21T17:26:59.78253Z","shell.execute_reply":"2023-02-21T17:27:01.808485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizerd_test_text = vectorizer(X_test.values)\n\n# testset = tf.data.Dataset.from_tensor_slices((vectorizerd_test_text))\n# testset = dataset.cache()\n# testset = dataset.shuffle(160000)\n# testset = dataset.batch(8) \n# testset = dataset.prefetch(8)","metadata":{"papermill":{"duration":0.142232,"end_time":"2023-02-20T01:36:57.091974","exception":false,"start_time":"2023-02-20T01:36:56.949742","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:27:01.810747Z","iopub.execute_input":"2023-02-21T17:27:01.811232Z","iopub.status.idle":"2023-02-21T17:27:01.832149Z","shell.execute_reply.started":"2023-02-21T17:27:01.811194Z","shell.execute_reply":"2023-02-21T17:27:01.831267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\n\nfor input_text in vectorizerd_test_text:\n    \n    pred = model.predict(np.expand_dims(input_text, 0))\n    \n    preds.append(pred)","metadata":{"papermill":{"duration":199.105477,"end_time":"2023-02-20T01:40:16.310621","exception":false,"start_time":"2023-02-20T01:36:57.205144","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:27:01.833477Z","iopub.execute_input":"2023-02-21T17:27:01.833957Z","iopub.status.idle":"2023-02-21T17:29:48.801739Z","shell.execute_reply.started":"2023-02-21T17:27:01.833919Z","shell.execute_reply":"2023-02-21T17:29:48.800781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds","metadata":{"papermill":{"duration":0.526976,"end_time":"2023-02-20T01:40:17.299882","exception":false,"start_time":"2023-02-20T01:40:16.772906","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:29:48.803445Z","iopub.execute_input":"2023-02-21T17:29:48.803833Z","iopub.status.idle":"2023-02-21T17:29:48.8085Z","shell.execute_reply.started":"2023-02-21T17:29:48.803775Z","shell.execute_reply":"2023-02-21T17:29:48.807464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_preds = []\n\nfor pred in preds:\n    \n    final_preds.append(output(pred))\n\nlen(final_preds)","metadata":{"papermill":{"duration":0.494756,"end_time":"2023-02-20T01:40:18.257516","exception":false,"start_time":"2023-02-20T01:40:17.76276","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:29:48.810061Z","iopub.execute_input":"2023-02-21T17:29:48.810686Z","iopub.status.idle":"2023-02-21T17:29:48.828717Z","shell.execute_reply.started":"2023-02-21T17:29:48.810651Z","shell.execute_reply":"2023-02-21T17:29:48.827623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final_preds","metadata":{"papermill":{"duration":0.479561,"end_time":"2023-02-20T01:40:19.241216","exception":false,"start_time":"2023-02-20T01:40:18.761655","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:29:48.830419Z","iopub.execute_input":"2023-02-21T17:29:48.830776Z","iopub.status.idle":"2023-02-21T17:29:48.83863Z","shell.execute_reply.started":"2023-02-21T17:29:48.830741Z","shell.execute_reply":"2023-02-21T17:29:48.837663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_sample = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\n\nsub_sample","metadata":{"papermill":{"duration":0.508115,"end_time":"2023-02-20T01:40:20.258992","exception":false,"start_time":"2023-02-20T01:40:19.750877","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:29:48.840002Z","iopub.execute_input":"2023-02-21T17:29:48.840432Z","iopub.status.idle":"2023-02-21T17:29:48.86077Z","shell.execute_reply.started":"2023-02-21T17:29:48.840397Z","shell.execute_reply":"2023-02-21T17:29:48.859722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_sample['target'] = final_preds\n\nsub_sample['target'] = sub_sample['target'].astype('int')\n\nsub_sample.to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":0.525285,"end_time":"2023-02-20T01:40:21.248147","exception":false,"start_time":"2023-02-20T01:40:20.722862","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:29:48.8625Z","iopub.execute_input":"2023-02-21T17:29:48.862878Z","iopub.status.idle":"2023-02-21T17:29:48.874941Z","shell.execute_reply.started":"2023-02-21T17:29:48.862843Z","shell.execute_reply":"2023-02-21T17:29:48.873934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/working/submission.csv')\n\nsubmission","metadata":{"papermill":{"duration":0.490571,"end_time":"2023-02-20T01:40:22.201036","exception":false,"start_time":"2023-02-20T01:40:21.710465","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-02-21T17:29:48.881434Z","iopub.execute_input":"2023-02-21T17:29:48.881697Z","iopub.status.idle":"2023-02-21T17:29:48.897128Z","shell.execute_reply.started":"2023-02-21T17:29:48.881673Z","shell.execute_reply":"2023-02-21T17:29:48.896003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# End","metadata":{"papermill":{"duration":0.467476,"end_time":"2023-02-20T01:40:23.392322","exception":false,"start_time":"2023-02-20T01:40:22.924846","status":"completed"},"tags":[]}}]}